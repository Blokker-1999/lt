<chapter><title>Disk Management</title>
<section><title>Hard disk devices</title>
	<section><title>Terminology</title>
		<para>Data is commonly stored on magnetic or optical <command>disk platters</command><indexterm><primary>disk platters</primary></indexterm>. The platters are rotated (at high speeds). Data is read by <command>heads</command><indexterm><primary>head (hard disk device)</primary></indexterm>, which are very close to the surface of the platter, without touching it! The heads are mounted on an arm (sometimes called a comb).</para>
		<para>Data is written in concentric circles or <command>tracks</command><indexterm><primary>track</primary></indexterm>. Track zero is (usually ?) on the inside. The time it takes to position the head over a certain track is called the <command>seek time</command><indexterm><primary>seek time</primary></indexterm>. Often the platters are stacked on top of each other, hence the set of tracks accessible at a certain position of the comb forms a <command>cylinder</command><indexterm><primary>cylinder</primary></indexterm>. Tracks are divided into 512 byte <command>sectors</command><indexterm><primary>sector</primary></indexterm>, with more unused space (<command>gap</command>) between the sectors on the outside of the platter. </para>
		<para>When you break down the advertised <command>access time</command><indexterm><primary>access time</primary></indexterm> of a hard drive, you will notice that most of that time is taken by movement of the heads (about 65%) and <command>rotational latency</command><indexterm><primary>rotational latency</primary></indexterm> (about 30%). </para>
		<para>Random access hard disk devices have an abstraction layer called <command>block device</command><indexterm><primary>block device</primary></indexterm> to enable formatting in fixed-size (usually 512 bytes) blocks. Blocks can be accessed independent of access to other blocks. You can recognize a block device by the letter b as first character of ls -l.</para>
		<screen>
[root@RHEL4b ~]# ls -l /dev/sda*
brw-rw----  1 root disk 8, 0 Aug  4 22:55 /dev/sda
brw-rw----  1 root disk 8, 1 Aug  4 22:55 /dev/sda1
brw-rw----  1 root disk 8, 2 Aug  4 22:55 /dev/sda2
[root@RHEL4b ~]#
		</screen>
	</section>	
	<section><title>IDE or SCSI</title>
		<para>Actually, the title should be <command>ATA</command><indexterm><primary>ATA</primary></indexterm> or <command>SCSI</command><indexterm><primary>SCSI</primary></indexterm>, since IDE is an ATA-compatible device. Most desktops use ATA devices. ATA allows two devices per bus, one <command>master</command><indexterm><primary>master (hard disk device)</primary></indexterm> and one <command>slave</command><indexterm><primary>slave (hard disk device)</primary></indexterm>. Unless your controller and devices support <command>cable select</command><indexterm><primary>cable select</primary></indexterm>, you have to set this manually with jumpers. With the introduction of <command>SATA</command><indexterm><primary>SATA</primary></indexterm> (Serial ATA), the original ATA was renamed to <command>Parallel ATA</command><indexterm><primary>Parallel ATA</primary></indexterm>. Optical drives often use <command>atapi</command><indexterm><primary>atapi</primary></indexterm>, which is an ATA interface using the SCSI communication protocol.</para>
		<para>When using the <command>Small Computer System Interface</command>, each device gets a unique <command>SCSI ID</command><indexterm><primary>SCSI ID</primary></indexterm>. The SCSI controller also needs a SCSI ID, do not use this ID for a SCSI-attached device. Older 8-bit SCSI is now called <command>narrow</command>, whereas 16-bit is <command>wide</command>. When the bus speeds was doubled to 10Mhz, this was known as <command>fast SCSI</command>. Doubling to 20Mhz made it <command>ultra SCSI</command>. Take a look at http://en.wikipedia.org/wiki/SCSI for more SCSI-standards. </para>
	</section>
	<section><title>Device Naming</title>
		<para>All ATA drives on your system will start with <command>/dev/hd</command><indexterm><primary>/dev/hdX</primary></indexterm> followed by a unit letter. The master hdd on the first ATA controller is /dev/hda, the slave is /dev/hdb. For the second controller, the names of the devices are /dev/hdc and /dev/hdd.</para>
		
<table frame='all'><title>IDE device naming</title>
<?dbfo table-width="70%" ?>
<tgroup cols='3' align='left' colsep='1' rowsep='1'>
<colspec colname='controller' align="center"/>
<colspec colname='connection' align="center"/>
<colspec colname='device name' align="center"/>
<thead>
<row>
  <entry>Controller</entry>
  <entry>Connection</entry>
  <entry>Device Name</entry>
</row>
</thead>
<tbody>
<row>
  <entry morerows='1' valign='middle'>IDE0</entry>
  <entry>master</entry>
  <entry>/dev/hda</entry>
</row>
<row>
  <entry>slave</entry>
  <entry>/dev/hdb</entry>
</row>
<row>
  <entry morerows='1' valign='middle'>IDE1</entry>
  <entry>master</entry>
  <entry>/dev/hdc</entry>
</row>
<row>
  <entry>slave</entry>
  <entry>/dev/hdd</entry>
</row>
</tbody>
</tgroup>
</table>

		<para>SCSI drives follow a similar scheme, but all start with <command>/dev/sd</command><indexterm><primary>/dev/sdX</primary></indexterm>. When you run out of letters (after /dev/sdz), you can continue with /dev/sdaa and /dev/sdab and so on. (We will see later on that LVM volumes are commonly seen as /dev/md0, /dev/md1 etc)</para>
		<para>Below a <command>sample</command> of how SCSI devices on a linux can be named. Adding a SCSI disk or RAID controller with a lower SCSI address will change the naming scheme (shifting the higher SCSI addresses one letter further in the alphabet).</para>
<table frame='all'><title>SCSI device naming</title>
<?dbfo table-width="80%" ?>
<tgroup cols='3' align='left' colsep='1' rowsep='1'>
<colspec colname='device' colwidth="2.5*" align="center"/>
<colspec colname='SCSI address' colwidth="1.5*" align="center"/>
<colspec colname='linux device name' colwidth="2*" align="center"/>
<thead>
<row>
  <entry>Device</entry>
  <entry>SCSI ID</entry>
  <entry>Device Name</entry>
</row>
</thead>

<tbody>
<row>
  <entry>Disk 0</entry>
  <entry>0</entry>
  <entry>/dev/sda</entry>
</row>
<row>
  <entry>Disk 1</entry>
  <entry>1</entry>
  <entry>/dev/sdb</entry>
</row>
<row>
  <entry>RAID Controller 0</entry>
  <entry>5</entry>
  <entry>/dev/sdc</entry>
</row>
<row>
  <entry>RAID Controller 1</entry>
  <entry>6</entry>
  <entry>/dev/sdd</entry>
</row>
</tbody>
</tgroup>
</table>
	<para>To get more information about the naming of devices and their major and minor number, visit http://www.lanana.org/docs/device-list/devices.txt .</para>
	</section>
	<section><title>Erasing a hard disk</title>
		<para>Before selling your old hard disk on the internet, it might be a good idea to really erase it. By simply repartitioning or even after a new mkfs command, some people will still be able to read most of the data on the disk. Although technically the <command>badblocks</command><indexterm><primary>badblocks(1)</primary></indexterm> tool is meant to look for bad blocks, you can use it to erase a disk. Since this is really writing to every sector of the disk, it can take a long time!</para>
		<screen>
root@RHELv4u2:~# badblocks -ws /dev/sdb
Testing with pattern 0xaa: done                        
Reading and comparing: done                        
Testing with pattern 0x55: done                        
Reading and comparing: done                        
Testing with pattern 0xff: done                        
Reading and comparing: done                        
Testing with pattern 0x00: done                        
Reading and comparing: done                        
		</screen>
	</section>
	<section><title>fdisk</title>
		<para>You can start by using <command>fdisk</command><indexterm><primary>fdisk(1)</primary></indexterm> to find out what kind of disks are seen by the kernel. Below the result on Debian, with two <command>ATA-IDE disks</command> present.</para>
		<screen>
root@barry:~# fdisk -l | grep Disk
Disk /dev/hda: 60.0 GB, 60022480896 bytes
Disk /dev/hdb: 81.9 GB, 81964302336 bytes
		</screen>
		<para>And here an example of <command>SATA disks</command> on a laptop with Ubuntu. SATA hard disks are presented to you with the SCSI /dev/sdx notation.</para>
		<screen>
root@laika:~# fdisk -l | grep Disk
Disk /dev/sda: 100.0 GB, 100030242816 bytes
Disk /dev/sdb: 100.0 GB, 100030242816 bytes
		</screen>
		<para>And last but not least, an overview of disks on a RHEL4u3 server with two real 72GB <command>SCSI disks</command>. This server is attached to a NAS with four <command>NAS disks</command> of half a terabyte. On the NAS disks, four LVM software RAID devices are configured.</para>
		<screen>
[root@tsvtl1 ~]# fdisk -l | grep Disk
Disk /dev/sda: 73.4 GB, 73407488000 bytes
Disk /dev/sdb: 73.4 GB, 73407488000 bytes
Disk /dev/sdc: 499.0 GB, 499036192768 bytes
Disk /dev/sdd: 499.0 GB, 499036192768 bytes
Disk /dev/sde: 499.0 GB, 499036192768 bytes
Disk /dev/sdf: 499.0 GB, 499036192768 bytes
Disk /dev/md0: 271 MB, 271319040 bytes
Disk /dev/md2: 21.4 GB, 21476081664 bytes
Disk /dev/md3: 21.4 GB, 21467889664 bytes
Disk /dev/md1: 21.4 GB, 21476081664 bytes
		</screen>
		<para>You can also use fdisk to obtain information about one specific hard disk device.</para>
		<screen>
[root@rhel4 ~]# fdisk -l /dev/sda

Disk /dev/sda: 12.8 GB, 12884901888 bytes
255 heads, 63 sectors/track, 1566 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes

   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          13      104391   83  Linux
/dev/sda2              14        1566    12474472+  8e  Linux LVM
		</screen>
		<para>Later we will use fdisk to do dangerous stuff like creating and deleting partitions.</para>
	</section>
	<section><title>hdparm</title>
		<para>To obtain (or set) information and parameters about an ATA (or SATA) hard disk device, you can use <command>hdparm</command><indexterm><primary>hdparm(1)</primary></indexterm>. The -i and -I options will give you even more information about the physical properties of the device.</para>
		<screen>
root@laika:~# hdparm /dev/sdb

/dev/sdb:
 IO_support   =  0 (default 16-bit)
 readonly     =  0 (off)
 readahead    = 256 (on)
 geometry     = 12161/255/63, sectors = 195371568, start = 0
		</screen>
	</section>
	<section><title>dmesg</title>
		<para>Kernel boot messages can be seen after boot with <command>dmesg</command><indexterm><primary>dmesg(1)</primary></indexterm>. Since hard disk devices are detected by the kernel during boot, you can also use dmesg to find information.</para>
		<screen>
root@barry:~# dmesg | grep "[hs]d[a-z]"
Kernel command line: root=/dev/hda1 ro 
    ide0: BM-DMA at 0xfc00-0xfc07, BIOS settings: hda:DMA, hdb:DMA
    ide1: BM-DMA at 0xfc08-0xfc0f, BIOS settings: hdc:DMA, hdd:DMA
hda: ST360021A, ATA DISK drive
hdb: Maxtor 6Y080L0, ATA DISK drive
hdc: SONY DVD RW DRU-510A, ATAPI CD/DVD-ROM drive
hdd: SONY DVD RW DRU-810A, ATAPI CD/DVD-ROM drive
hda: max request size: 128KiB
hda: 117231408 sectors (60022 MB) w/2048KiB Cache, CHS=65535/16/63, UDMA
 hda: hda1 hda2
hdb: max request size: 128KiB
hdb: 160086528 sectors (81964 MB) w/2048KiB Cache, CHS=65535/16/63, UDMA
 hdb: hdb1 hdb2
hdc: ATAPI 32X DVD-ROM DVD-R CD-R/RW drive, 8192kB Cache, UDMA(33)
hdd: ATAPI 40X DVD-ROM DVD-R CD-R/RW drive, 2048kB Cache, UDMA(33)
...
		</screen>
	</section>
	<section><title>/proc/scsi/scsi</title>
		<para>You can also look at the contents of <command>/proc/scsi/scsi</command><indexterm><primary>/proc/scsi/scsi</primary></indexterm>.</para>
		<screen>
root@shaka:~# cat /proc/scsi/scsi 
Attached devices:
Host: scsi0 Channel: 00 Id: 00 Lun: 00
  Vendor: Adaptec  Model: RAID5            Rev: V1.0
  Type:   Direct-Access                    ANSI SCSI revision: 02
Host: scsi1 Channel: 00 Id: 00 Lun: 00
  Vendor: SEAGATE  Model: ST336605FSUN36G  Rev: 0438
  Type:   Direct-Access                    ANSI SCSI revision: 03
  root@shaka:~# 
		</screen>
	</section>
	<section><title>scsi_info</title>
		<para>You can also use <command>scsi_info</command><indexterm><primary>scsi_info(1)</primary></indexterm>.</para> 
		<screen>
root@shaka:~# scsi_info /dev/sdb
SCSI_ID="0,0,0"
HOST="1"
MODEL="SEAGATE ST336605FSUN36G"
FW_REV="0438"
root@shaka:~#
		</screen>
	</section>
	<section><title>lsscsi</title>
		<para>And even <command>lsscsi</command><indexterm><primary>lsscsi(1)</primary></indexterm> if it is installed.</para>
		<screen>
root@shaka:~# lsscsi 
[0:0:0:0]    disk    Adaptec  RAID5            V1.0  /dev/sda
[1:0:0:0]    disk    SEAGATE  ST336605FSUN36G  0438  /dev/sdb
root@shaka:~# 
		</screen>
	</section>
	<section><title>Practice hard disk devices</title>
		<para>1. Use dmesg to make a list of hard disk devices (ide,ata,sata,scsi) detected at bootup.</para>
		<para>2. Use fdisk to find the total size of all hard disk devices on your system.</para>
		<para>3. Stop a virtual machine, add a virtual 10 gigabyte SCSI hard disk and a virtual 100 megabyte SCSI hard disk.</para>
		<para>4. Use dmesg and fdisk (with grep) to display some information about the new disks.</para>
		<para>5. Use badblocks to completely erase the 100 mb hard disk.</para>
		<para>6. Look at /proc/scsi/scsi.</para>
	</section>
</section>
<section><title>Partitions</title>
	<section><title>About Partitions</title>
		<para>Linux requires you to create one or more <command>partitions</command><indexterm><primary>partition</primary></indexterm> aka <command>slices</command><indexterm><primary>slice</primary></indexterm>. <emphasis>Please don't break your head on the difference between a partition and a slice. Different tools have different interpretations of which is which.</emphasis> Although partitions reside on the same hard disk device, you can (almost) see them as independent of each other.</para>
		<para>A partition's <command>geometry</command> and size is usually defined by a starting and ending cylinder (sometimes by head or even sector). Partitions can be of type <command>primary</command><indexterm><primary>primary partition</primary></indexterm> (maximum four), <command>extended</command><indexterm><primary>extended partition</primary></indexterm> (maximum one) or <command>logical</command><indexterm><primary>logical drive</primary></indexterm> (contained within the extended partition). Each partition has a <command>type field</command> that contains a code. This determines the computers operating system or the partitions file system.</para>
	</section>
	<section><title>Partition naming</title>
		<para>We saw before that hard disk devices are named /dev/hdx or /dev/sdx with x depending on the hardware configuration. Next is the partition number, starting the count at 1. Hence the four (possible) primary partitions are numbered 1 to 4. Logical partition counting always starts at 5. Thus /dev/hda2 is the second partition on the first ATA hard disk device, and /dev/hdb5 is the first logical partition on the second ATA hard disk device. Same for SCSI, /dev/sdb3 is the third partition on the second SCSI disk.</para>

<table frame='all'><title>Partition naming</title>
<?dbfo table-width="50%" ?>
<tgroup cols='2' align='left' colsep='1' rowsep='1'>
<colspec colname='c1' colwidth="3*" align="center"/>
<colspec colname='c2' colwidth="1*" align="center"/>
<thead>
<row>
  <entry>Partition Type</entry>
  <entry>naming</entry>
</row>
</thead>
<tbody>
<row>
  <entry>Primary (max 4)</entry>
  <entry>1-4</entry>
</row>
<row>
  <entry>Extended (max 1)</entry>
  <entry>1-4</entry>
</row>
<row>
  <entry>Logical</entry>
  <entry>5-</entry>
</row>
</tbody>
</tgroup>
</table>
	</section>
	<section><title>fdisk -l</title>
		<para>In the <command>fdisk -l</command><indexterm><primary>fdisk(1)</primary></indexterm> example below you can see that two partitions exist on /dev/sdb2. The first partition spans 31 cylinders and contains a Linux swap partition. The second partition is much bigger.</para>
		<screen>
root@laika:~# fdisk -l /dev/sdb

Disk /dev/sdb: 100.0 GB, 100030242816 bytes
255 heads, 63 sectors/track, 12161 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes

   Device Boot    Start      End     Blocks   Id  System
/dev/sdb1             1       31     248976   82  Linux swap / Solaris
/dev/sdb2            32    12161   97434225   83  Linux
root@laika:~#		
		</screen>
	</section>
	<section><title>other tools</title>
		<para>You might be interested in more GUI-oriented alternatives to fdisk and parted like cfdisk, sfdisk and gparted.</para>
	</section>
	<section><title>Partitioning new disks</title>
		<para>In the example below, we bought a new disk for our system. After the new hardware is properly attached, you can use <command>fdisk</command> and <command>parted</command><indexterm><primary>parted(1)</primary></indexterm> to create the necessary partition(s). This example uses fdisk, but there is nothing wrong with using parted.</para>
		<para>First, we check with <command>fdisk -l</command> whether Linux can see the new disk. Yes it does, the new disk is seen as /dev/sdb, but it does not have any partitions yet.</para>
		<screen>
root@RHELv4u2:~# fdisk -l
		
Disk /dev/sda: 12.8 GB, 12884901888 bytes
255 heads, 63 sectors/track, 1566 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start      End      Blocks   Id  System
/dev/sda1   *       1        13      104391   83  Linux
/dev/sda2          14      1566    12474472+  8e  Linux LVM
		
Disk /dev/sdb: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Disk /dev/sdb doesn't contain a valid partition table
		</screen>
		<para>Then we create a partition with fdisk on /dev/sdb. First we start the fdisk tool with /dev/sdb as argument. Be very very careful not to partition the wrong disk!!</para>
		<screen>
root@RHELv4u2:~# fdisk /dev/sdb
Device contains neither a valid DOS partition table, nor Sun, SGI...
Building a new DOS disklabel. Changes will remain in memory only,
until you decide to write them. After that, of course, the previous
content won't be recoverable.
		
Warning: invalid flag 0x0000 of partition table 4 will be corrected...
		</screen>
		<para>Inside the fdisk tool, we can issue the <command>p</command><indexterm><primary>fdisk(1)</primary></indexterm> command to see the current disks partition table.</para>
		<screen>
Command (m for help): p
		
Disk /dev/sdb: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start         End      Blocks   Id  System
		
		</screen>
		<para>No partitions exist yet, so we issue <command>n</command> to create a new partition. We choose p for primary, 1 for the partition number, 1 for the start cylinder and 14 for the end cylinder.</para>
		<screen>
Command (m for help): n
Command action
e   extended
p   primary partition (1-4)
p
Partition number (1-4): 1
First cylinder (1-130, default 1): 
Using default value 1
Last cylinder or +size or +sizeM or +sizeK (1-130, default 130): 14
		</screen>
		<para>We can now issue p again to verify our changes, but they are not yet written to disk. This means we can still cancel this operation! But it looks good, so we use <command>w</command> to write the changes to disk, and then quit the fdisk tool.</para>
		<screen>
Command (m for help): p
	
Disk /dev/sdb: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start         End      Blocks   Id  System
/dev/sdb1               1          14      112423+  83  Linux
		
Command (m for help): w
The partition table has been altered!
		
Calling ioctl() to re-read partition table.
Syncing disks.
root@RHELv4u2:~#
		</screen>
		<para>Let's verify again with <command>fdisk -l</command><indexterm><primary>fdisk(1)</primary></indexterm> to make sure reality fits our dreams. Indeed, the screenshot below now shows a partition on /dev/sdb. </para>
		<screen>
root@RHELv4u2:~# fdisk -l
		
Disk /dev/sda: 12.8 GB, 12884901888 bytes
255 heads, 63 sectors/track, 1566 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start        End      Blocks   Id  System
/dev/sda1   *        1         13      104391   83  Linux
/dev/sda2           14       1566    12474472+  8e  Linux LVM
		
Disk /dev/sdb: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start         End      Blocks   Id  System
/dev/sdb1               1          14      112423+  83  Linux
root@RHELv4u2:~# 
		</screen>
	</section>
	<section><title>Master Boot Record</title>
		<para>The partition table information is written in the <command>Master Boot Record</command><indexterm><primary>master boot record</primary></indexterm> or <command>MBR</command><indexterm><primary>mbr</primary></indexterm>. You can use <command>dd</command><indexterm><primary>dd(1)</primary></indexterm> to copy the mbr to a file.</para>
		<para>This example copies the master boot record from the first SCSI hard disk.</para>
		<screen>dd if=/dev/sda of=/SCSIdisk.mbr bs=512 count=1</screen>
		<para>The same tool can also be used to wipe out all information about partitions on a disk. This example writes zeroes over the master boot record.</para>
		<screen>dd if=/dev/zero of=/dev/sda bs=512 count=1</screen>
	</section>
	<section><title>partprobe</title>
		<para>Don't forget that after restoring a Master Boot Record with dd, that you need to force the kernel to reread the partition table with  <command>partprobe</command><indexterm><primary>partprobe(1)</primary></indexterm>. After running partprobe, the partitions can be used again.</para>
		<screen>
[root@RHEL5 ~]# partprobe 
[root@RHEL5 ~]#
		</screen>
	</section>
	<section><title>Practice Partitions</title>
		<para>1. Use fdisk and df to display existing partitions and sizes. Compare the output of the two commands.</para>
		<para>2. Create a 50MB primary partition on a small disk.</para>
		<para>3. Create a 200MB primary partition and two 100MB logical drives on a big disk.</para>
		<para>4. Use df and fdisk -l to verify your work.</para>
		<para>5. Take a backup of the partition table containing your 200MB primary and 100MB logical drives. Destroy the partitions with fdisk. Then restore your backup.</para>
		<para></para>
		<para></para>
	</section>
</section>
<section><title>File Systems</title>
	<section><title>About file systems</title>
		<para>After you are finished partitioning the hard disk, you can put a <command>file system</command><indexterm><primary>file system</primary></indexterm> on each partition. A file system is a way of organizing files on your partition. Besides file-based storage, file systems usually include <command>directories</command><indexterm><primary>directory</primary></indexterm> and <command>access control</command>, and contain meta information about files like access times, modification times and file ownership. </para>
		<para>The properties (length, character set, ...) of filenames are determined by the file system you choose. Directories are usually implemented as files, you will have to learn how this is implemented! Access control in file systems is tracked by user ownership (and group owner- and membership) in combination with one or more access control lists.</para>
	</section>
	<section><title>Common file systems</title>
		<section><title>ext2 and ext3</title>
			<para>Once the most common Linux file systems is the <command>ext2</command><indexterm><primary>ext2</primary></indexterm> (the second extended) file system. A disadvantage is that file system checks on ext2 can take a long time. You will see that ext2 is being replaced by <command>ext3</command><indexterm><primary>ext3</primary></indexterm> on most Linux machines. They are essentially the same, except for the <command>journaling</command><indexterm><primary>journaling</primary></indexterm> which is only present in ext3.</para>
			<para>Journaling means that changes are first written to a journal on the disk. The journal is flushed regularly, writing the changes in the file system. Journaling keeps the file system in a consistent state, so you don't need a file system check after an unclean shutdown or power failure.</para>
			<para>You can create these file systems with the <command>/sbin/mkfs</command><indexterm><primary>mkfs(1)</primary></indexterm> or <command>/sbin/mke2fs</command><indexterm><primary>mke2fs(1)</primary></indexterm> commands. Use <command>mke2fs -j</command> to create an ext3 file system. You can convert an ext2 to ext3 with <command>tune2fs -j</command><indexterm><primary>tune2fs(1)</primary></indexterm>. You can mount an ext3 file system as ext2, but then you lose the journaling. Do not forget to run <command>mkinitrd</command><indexterm><primary>mkinitrd(1)</primary></indexterm> if you are booting from this device.</para>
		</section>
		<section><title>vfat</title>
			<para>The <command>vfat</command><indexterm><primary>vfat</primary></indexterm> file system exists in a couple of forms : FAT12 for floppy disks, <command>FAT16</command><indexterm><primary>fat16</primary></indexterm> on DOS, and <command>FAT32</command><indexterm><primary>fat32</primary></indexterm> for larger disks. The Linux VFAT implementation supports all of these, but vfat lacks a lot of features like security and links. FAT disks can be read by every operating system, and are used a lot for digital cameras, USB sticks and to exchange data between different OS'ses on a home user's computer.</para>
		</section>
		<section><title>ISO 9660</title>
			<para><command>ISO 9660</command><indexterm><primary>iso9660</primary></indexterm> is the standard format for CD-ROM's. Chances are you will encounter this file system also on your harddisk in the form of images of CD-ROM's (often with the .ISO extension). The ISO 9660 standard limits filenames to the 8.3 format. The Unix world didn't like this, and thus added the <command>Rock Ridge</command><indexterm><primary>rock ridge</primary></indexterm> extensions, which allows for filenames up to 255 characters and Unix-style file-modes, ownership and symbolic links. Another extensions to ISO 9660 is <command>Joliet</command><indexterm><primary>joliet</primary></indexterm>, which adds 64 unicode characters to the filename. The <command>El Torito</command><indexterm><primary>el torito</primary></indexterm> standard extends ISO 9660 to be able to boot from CD-ROM's.</para>
		</section>
		<section><title>UDF</title>
			<para>Most optical media today (including CD's and DVD's) use <command>UDF</command><indexterm><primary>udf</primary></indexterm>, the Universal Disk Format.</para>
		</section>
		<section><title>swap</title>
			<para>All things considered, swap is not a file system. But to use a partition as a <command>swap partition</command><indexterm><primary>swap partition</primary></indexterm> it must be formatted as swap space.</para>
		</section>
		<section><title>others...</title>
			<para>You might encounter <command>reiserfs</command><indexterm><primary>reiserfs</primary></indexterm> on Linux systems, but it is not common on Red Hat. Maybe you will see a <command>zfs</command><indexterm><primary>zfs</primary></indexterm>, or one of the dozen other file systems available.</para>
		</section>
	</section>
	<section><title>Putting a file system on a partition</title>
		<para>We now have a fresh partition. The system binaries to make file systems can be found with ls.</para>
		<screen>
[root@RHEL4b ~]# ls -lS /sbin/mk*
-rwxr-xr-x  3 root root 34832 Apr 24  2006 /sbin/mke2fs
-rwxr-xr-x  3 root root 34832 Apr 24  2006 /sbin/mkfs.ext2
-rwxr-xr-x  3 root root 34832 Apr 24  2006 /sbin/mkfs.ext3
-rwxr-xr-x  3 root root 28484 Oct 13  2004 /sbin/mkdosfs
-rwxr-xr-x  3 root root 28484 Oct 13  2004 /sbin/mkfs.msdos
-rwxr-xr-x  3 root root 28484 Oct 13  2004 /sbin/mkfs.vfat
-rwxr-xr-x  1 root root 20313 Apr 10  2006 /sbin/mkinitrd
-rwxr-x---  1 root root 15444 Oct  5  2004 /sbin/mkzonedb
-rwxr-xr-x  1 root root 15300 May 24  2006 /sbin/mkfs.cramfs
-rwxr-xr-x  1 root root 13036 May 24  2006 /sbin/mkswap
-rwxr-xr-x  1 root root  6912 May 24  2006 /sbin/mkfs
-rwxr-xr-x  1 root root  5905 Aug  3  2004 /sbin/mkbootdisk
[root@RHEL4b ~]# 
		</screen>
		<para>It is time for you to read the manual pages of <command>mkfs</command><indexterm><primary>mkfs(1)</primary></indexterm> and <command>mke2fs</command><indexterm><primary>mke2fs(1)</primary></indexterm>. In the example below, you see the creation of an <command>ext2 file system</command><indexterm><primary>ext2</primary></indexterm> on /dev/sdb1. In real life, you might want to use options like -m0 and -j.</para>
		<screen>
root@RHELv4u2:~# mke2fs /dev/sdb1
mke2fs 1.35 (28-Feb-2004)
Filesystem label=
OS type: Linux
Block size=1024 (log=0)
Fragment size=1024 (log=0)
28112 inodes, 112420 blocks
5621 blocks (5.00%) reserved for the super user
First data block=1
Maximum filesystem blocks=67371008
14 block groups
8192 blocks per group, 8192 fragments per group
2008 inodes per group
Superblock backups stored on blocks: 
8193, 24577, 40961, 57345, 73729
		
Writing inode tables: done                            
Writing superblocks and filesystem accounting information: done
		
This filesystem will be automatically checked every 37 mounts or
180 days, whichever comes first.  Use tune2fs -c or -i to override.
		</screen>
	</section>
	<section><title>Tuning a file system</title>
		<para>You can use <command>tune2fs</command><indexterm><primary>tune2fs(1)</primary></indexterm> to list and set file system settings. The first screenshot lists the reserved space for root (which is set at five percent).</para>
		<screen>
[root@rhel4 ~]# tune2fs -l /dev/sda1 | grep -i "block count"
Block count:              104388
Reserved block count:     5219
[root@rhel4 ~]#
		</screen>
		<para>This example changes this value to ten percent. You can use tune2fs while the file system is active, even if it is the root file system (as in this example).</para>
		<screen>
[root@rhel4 ~]# tune2fs -m10 /dev/sda1 
tune2fs 1.35 (28-Feb-2004)
Setting reserved blocks percentage to 10 (10430 blocks)
[root@rhel4 ~]# tune2fs -l /dev/sda1 | grep -i "block count"
Block count:              104388
Reserved block count:     10430
[root@rhel4 ~]# 
		</screen>
	</section>
	<section><title>Checking a file system</title>
		<para>The <command>fsck</command><indexterm><primary>fsck(1)</primary></indexterm> command is a front end tool used to check a file system for errors.</para>
		<screen>
[root@RHEL4b ~]# ls /sbin/*fsck*
/sbin/dosfsck  /sbin/fsck         /sbin/fsck.ext2  /sbin/fsck.msdos
/sbin/e2fsck   /sbin/fsck.cramfs  /sbin/fsck.ext3  /sbin/fsck.vfat
[root@RHEL4b ~]#
		</screen>
		<para>The last column in <command>/etc/fstab</command><indexterm><primary>/etc/fstab</primary></indexterm> is used to determine whether a file system should be checked at bootup.</para>
		<screen>
[paul@RHEL4b ~]$ grep ext /etc/fstab 
/dev/VolGroup00/LogVol00   /             ext3    defaults        1 1
LABEL=/boot                /boot         ext3    defaults        1 2
[paul@RHEL4b ~]$
		</screen>
		<para>Manually checking a mounted file system results in a warning from fsck.</para>
		<screen>
[root@RHEL4b ~]# fsck /boot
fsck 1.35 (28-Feb-2004)
e2fsck 1.35 (28-Feb-2004)
/dev/sda1 is mounted.  

WARNING!!!  Running e2fsck on a mounted filesystem may cause
SEVERE filesystem damage.

Do you really want to continue (y/n)? no

check aborted.
[root@RHEL4b ~]#
		</screen>
		<para>But after unmounting fsck and <command>e2fsck</command><indexterm><primary>e2fsck(1)</primary></indexterm> can be used to check an ext2 file system.</para>
		<screen>
[root@RHEL4b ~]# fsck  /boot
fsck 1.35 (28-Feb-2004)
e2fsck 1.35 (28-Feb-2004)
/boot: clean, 44/26104 files, 17598/104388 blocks
[root@RHEL4b ~]# fsck -p /boot
fsck 1.35 (28-Feb-2004)
/boot: clean, 44/26104 files, 17598/104388 blocks
[root@RHEL4b ~]# e2fsck -p /dev/sda1
/boot: clean, 44/26104 files, 17598/104388 blocks
[root@RHEL4b ~]#
		</screen>
	</section>
	<section><title>Practice File Systems</title>
		<para>1. List the filesystems that are known by your system.</para>
		<para>2. Create an ext2 filesystem on the 50MB partition.</para>
		<para>3. Create an ext3 filesystem on the 4GB primary and one of the 1GB logical drives.</para>
		<para>4. Set the reserved space for root on the logical drive to 0 percent.</para>
		<para>5. Verify your work with the usual commands.</para>
		<para>6. Put a reiserfs on one of the logical drives.</para>
	</section>
</section>
<section><title>Mounting</title>
	<para>Once you've put a file system on a partition, you can <command>mount</command><indexterm><primary>mount(1)</primary></indexterm> it. Mounting a file system makes it available for use, usually as a directory. We say <command>mounting a file system</command><indexterm><primary>mounting</primary></indexterm> instead of mounting a partition because we will see later that we can also mount file systems that do not exists on partitions.</para>
	<section><title>Mounting local disks</title>
		<para>On all Unix systems, every file and every directory is part of one big file tree. To access a file, you need to know the full path starting from the root directory. When adding a file system to your computer, you need to make it available somewhere in the file tree. The directory where you make a file system available is called a <command>mount point</command><indexterm><primary>mount point</primary></indexterm>. Once mounted, the new file system is accessible to users. The screenshot below shows the creation of a mount point, and the mounting of an ext2 partition on a newly added SCSI disk. </para>
		<screen>
root@RHELv4u2:~# mkdir /home/project55
root@RHELv4u2:~# mount -t ext2 /dev/sdb1 /home/project55/
root@RHELv4u2:~# ls /home/project55/
lost+found
root@RHELv4u2:~# 
		</screen>
		<para>Actually the explicit -t ext2 option to set the file system is not always necesarry. The mount command is able to automatically detect a lot of file systems on partitions.</para>
	</section>
	<section><title>Displaying mounted file systems</title>
		<para>To view all mounted file systems, look at the files <command>/proc/mounts</command><indexterm><primary>/proc/mounts</primary></indexterm> or <command>/etc/mtab</command><indexterm><primary>/etc/mtab</primary></indexterm>. The kernel provides the info in /proc/mount in file form, but /proc/mount does not exist as a file on any hard disk. Looking at /proc/mount is the best way to be sure, since the information comes directly from the kernel. The /etc/mtab file on the other hand is updated by the mount command. Do not edit /etc/mtab manually!</para>
		<para>Another way to view all mounts is by issuing the <command>mount</command><indexterm><primary>mount(1)</primary></indexterm> command without any arguments. The screenshot below pipes the output of these three through grep, to only show our added SCSI disk.</para>
		<screen>
root@RHELv4u2:~# cat /proc/mounts | grep /dev/sdb
/dev/sdb1 /home/project55 ext2 rw 0 0
root@RHELv4u2:~# cat /etc/mtab | grep /dev/sdb
/dev/sdb1 /home/project55 ext2 rw 0 0
root@RHELv4u2:~# mount | grep /dev/sdb
/dev/sdb1 on /home/project55 type ext2 (rw)
		</screen>
		<para>A more user friendly way to look at mounted hard disks is <command>df</command><indexterm><primary>df(1)</primary></indexterm>. The df(diskfree) command has the added benefit of showing you the free space on each mounted disk. Like a lot of Linux commands, df supports the <command>-h</command> switch to make the output more <command>human readable</command>.</para>
		<screen>
root@RHELv4u2:~# df
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/mapper/VolGroup00-LogVol00
11707972   6366996   4746240  58% /
/dev/sda1             101086    9300    86567  10% /boot
none                  127988       0   127988   0% /dev/shm
/dev/sdb1             108865    1550   101694   2% /home/project55
root@RHELv4u2:~# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup00-LogVol00
12G  6.1G  4.6G  58% /
/dev/sda1              99M  9.1M   85M  10% /boot
none                  125M     0  125M   0% /dev/shm
/dev/sdb1             107M  1.6M  100M   2% /home/project55
		</screen>
	</section>
	<section><title>Permanent mounts</title>
		<para>Until now, we performed all mounts manually. This works nice, until the next reboot. Luckily there is a way to tell your computer to automatically mount certain file systems during boot. This is done using the file system table located in the <command>/etc/fstab</command><indexterm><primary>/etc/fstab</primary></indexterm> file. Below is a sample /etc/fstab file.</para>
		<screen>
root@RHELv4u2:~# cat /etc/fstab 
/dev/VolGroup00/LogVol00 /                ext3    defaults        1 1
LABEL=/boot             /boot             ext3    defaults        1 2
none                    /dev/pts          devpts  gid=5,mode=620  0 0
none                    /dev/shm          tmpfs   defaults        0 0
none                    /proc             proc    defaults        0 0
none                    /sys              sysfs   defaults        0 0
/dev/VolGroup00/LogVol01 swap             swap    defaults        0 0
		</screen>
		<para>By adding the following two lines, we can automate the mounting of these file systems. The first line is for our freshly added SCSI disk, the second line mounts an NFS share.</para>
		<screen>
/dev/sdb1                /home/project55      ext2    defaults    0 0
server12:/mnt/data/iso   /home/iso            nfs     defaults    0 0
		</screen>
	</section>
        <section><title>Disk Usage (du)</title>
                <para>The <command>du</command><indexterm><primary>du(1)</primary></indexterm> command can summarize disk usage for files and directories. Preventing du to go into subdirectories with the -s option will give you a total for that directory. This option is often used together with -h, so <command>du -sh</command> on a mount point gives the total amount used in that partition.</para>
                <screen>
root@pasha:~# du -sh /home/reet
881G     /home/reet
                </screen>
        </section>
        <section><title>Disk Free (df)</title>
                <para>In the <command>df -h</command><indexterm><primary>df(1)</primary></indexterm> example below you can see the size, free space, used gigabytes and percentage and mount point of a partition.</para>
                <screen>
root@laika:~# df -h | egrep -e "(sdb2|File)"
Filesystem            Size Used Avail Use% Mounted on
/dev/sdb2              92G   83G  8.6G  91% /media/sdb2
root@laika:~#
                </screen>
        </section>
	<section><title>Practice Mounting File Systems</title>
		<para>1. Mount the small 50MB partition on /home/project22.</para>
		<para>2. Mount the big primary partition on /mnt, the copy some files to it (everything in /etc). Then mount the partition as read only on /srv/nfs/salesnumbers.</para>
		<para>3. Verify your work with fdisk, df, mount. Also look in /etc and /proc to interesting files.</para>
		<para>4. Make both mounts permanent, test that it works.</para>
		<para>5. What happens when you mount a partition on a directory that contains some files ?</para>
		<para>6. What happens when you mount two partitions on the same mountpoint ?</para>
		<para>7. Describe the difference between these file searching commands: find, locate, updatedb, whereis, apropos and which.</para>
		<para>8. Perform a file system check on the partition mounted at /srv/nfs/salesnumbers.</para>
	</section>
</section>

<section><title>UUID and filesystems</title>
<section><title>About Unique Objects</title>
	<para>A <command>UUID</command><indexterm><primary>UUID</primary></indexterm> or <command>Universally Unique Identifier</command><indexterm><primary>Universally Unique Identifier</primary></indexterm>is used to uniquely identify objects. This 128bit standard allows anyone to create a unique UUID. Below we use the <command>vol_id</command><indexterm><primary>vol_id(1)</primary></indexterm> utility to display the UUID of an ext3 partition on a hard disk.</para>
	<screen>
root@laika:~# vol_id --uuid /dev/sda1
825d4b79-ec40-4390-8a71-9261df8d4c82
	</screen>
	<para>Red Hat Enterprise Linux 5 does not put the <command>vol_id</command> command in the PATH. But you can use <command>tune2fs</command><indexterm><primary>tune2fs(1)</primary></indexterm> or type the path to the vol_id command to display the UUID of a volume.</para>
	<screen>
[root@RHEL5 ~]# tune2fs -l /dev/sda1 | grep UUID
Filesystem UUID:          11cfc8bc-07c0-4c3f-9f64-78422ef1dd5c
[root@RHEL5 ~]# /lib/udev/vol_id -u /dev/sda1
11cfc8bc-07c0-4c3f-9f64-78422ef1dd5c
	</screen>
</section>
<section><title>Using UUID in /etc/fstab</title>
<para>You can use the UUID to make sure that a volume is universally uniquely identified in <command>/etc/fstab</command>. The device name can change depending on the disk devices that are present at boot time, but a UUID never changes.</para>
<para>First we use <command>tune2fs</command> to find the UUID.</para>
<screen>
[root@RHEL5 ~]# tune2fs -l /dev/sdc1 | grep UUID
Filesystem UUID:          7626d73a-2bb6-4937-90ca-e451025d64e8
</screen>
<para>Then we check that it is properly added to <command>/etc/fstab</command>, the UUID replaces the variable devicename /dev/sdc1.</para>
<screen>
[root@RHEL5 ~]# grep UUID /etc/fstab 
UUID=7626d73a-2bb6-4937-90ca-e451025d64e8 /home/pro42 ext3 defaults 0 0
</screen>
<para>Now we can mount the volume using the mountpoint defined in /etc/fstab.</para>
<screen>
[root@RHEL5 ~]# mount /home/pro42
[root@RHEL5 ~]# df -h | grep 42
/dev/sdc1             397M   11M  366M   3% /home/pro42
</screen>
<para>The real test now, is to remove /dev/sdb from the system, reboot the machine and see what happens. After the reboot, the disk previously known as /dev/sdc is now /dev/sdb.</para>
<screen>
[root@RHEL5 ~]# tune2fs -l /dev/sdb1 | grep UUID
Filesystem UUID:          7626d73a-2bb6-4937-90ca-e451025d64e8
</screen>
<para>And thanks to the UUID in /etc/fstab, the mountpoint is mounted on the same disk as before.</para>
<screen>
[root@RHEL5 ~]# df -h | grep sdb
/dev/sdb1             397M   11M  366M   3% /home/pro42
</screen>
</section>
<section><title>Practice UUID</title>
<para>1. Find the UUID of one of your ext3 partitions with tune2fs and vol_id. </para>
<para>2. USe this UUID in /etc/fstab and test that it works when a disk is removed (and the device name is changed). (You can edit settings in vmware to remove a hard disk.)</para>
<para></para>
<para></para>
</section>
</section>
<section><title>RAID</title>
	<section><title>Hardware or software</title>
		<para>Redundant Array of Independent Disks or <command>RAID</command><indexterm><primary>RAID</primary></indexterm> can be set up using hardware or software. Hardware RAID is more expensive, but offers better performance. Software RAID is cheaper and easier to manage, but it uses your CPU and your memory.</para>
	</section>
	<section><title>RAID levels</title>
		<section><title>RAID 0</title>
			<para>RAID 0 uses two or more disks, and is often called <command>striping</command><indexterm><primary>striped disk</primary></indexterm> (or stripe set, or striped volume). Data is divided in <command>chunks</command>, those chunks are evenly spread across every disk in the array. The main advantage of RAID 0 is that you can create <command>larger drives</command>. RAID 0 is the only RAID without redundancy.</para>
		</section>
		<section><title>JBOD</title>
			<para><command>JBOD</command><indexterm><primary>JBOD</primary></indexterm> uses two or more disks, and is often called <command>concatenating</command> (spanning, spanned set, or spanned volume). Data is written to the first disk, until it is full. Then data is written to the second disk... The main advantage of JBOD (Just a Bunch of Disks) is that you can create <command>larger drives</command>. JBOD offers no redundancy.</para>
		</section>
		<section><title>RAID 1</title>
			<para>RAID 1 uses exactly two disks, and is often called <command>mirroring</command><indexterm><primary>mirror</primary></indexterm> (or mirror set, or mirrored volume). All data written to the array is written on each disk. The main advantage of RAID 1 is <command>redundancy</command><indexterm><primary>RAID 1</primary></indexterm>. The main disadvantage is that you lose at least half of your available disk space (in other words, you at least double the cost).</para>
		</section>
		<section><title>RAID 2, 3 and 4 ?</title>
			<para>RAID 2 uses bit level striping, RAID 3 byte level, and RAID 4 is the same as RAID 5, but with a dedicated parity disk. This is actually slower than RAID 5, because every write would have to write parity to this one (bottleneck) disk. It is unlikely that you will ever see these RAID levels in production.</para>
		</section>
		<section><title>RAID 5</title>
			<para>RAID 5 uses <command>three</command> or more disks, each divided into chunks. Every time chunks are written to the array, one of the disks will receive a <command>parity</command><indexterm><primary>RAID 5</primary></indexterm> chunk. Unlike RAID 4, the parity chunk will alternate between all disks. The main advantage of this is that RAID 5 will allow for full data recovery in case of <command>one</command> hard disk failure.</para>
		</section>
		<section><title>RAID 6</title>
			<para>RAID 6 is very similar to RAID 5, but uses two parity chunks. RAID 6 protects against two hard disk failures.</para>
		</section>
		<section><title>RAID 0+1</title>
			<para>RAID 0+1 is a mirror(1) of stripes(0). This means you first create two RAID 0 stripe sets, and then you set them up as a mirror set. For example, when you have six 100GB disks, then the stripe sets are each 300GB. Combined in a mirror, this makes 300GB total. RAID 0+1 will survive one disk failure. It will only survive the second disk failure if this disk is in the same stripe set as the previous failed disk.</para>
		</section>
		<section><title>RAID 1+0</title>
			<para>RAID 1+0 is a stripe(0) of mirrors(1). For example, when you have six 100GB disks, then you first create three mirrors of 100GB each. You then stripe them together into a 300GB drive. In this example, as long as not all disks in the same mirror fail, it can survive up to three hard disk failures.</para>
		</section>
		<section><title>RAID 50</title>
			<para>RAID 5+0 is a stripe(0) of RAID 5 arrays. Suppose you have nine disks of 100GB, then you can create three RAID 5 arrays of 200GB each. You can then combine them into one large stripe set.</para>
		</section>
		<section><title>many others</title>
			<para>There are many other nested RAID combinations, like RAID 30, 51, 60, 100, 150, ...</para>
		</section>
	</section>
	<section><title>Building a software RAID array</title>
		<para>You can do this during the installation with Disk Druid (easy), or afterwards using the commandline (not so easy). </para>
		<para>First, you have to attach some disks to your computer. In this scenario, three brand new disks of one gigabyte each are added. Check with <command>fdisk -l</command><indexterm><primary>fdisk(1)</primary></indexterm> that they are connected.</para>
		<screen>
root@RHELv4u2:~# fdisk -l
		
Disk /dev/sda: 12.8 GB, 12884901888 bytes
255 heads, 63 sectors/track, 1566 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          13      104391   83  Linux
/dev/sda2              14        1566    12474472+  8e  Linux LVM
		
Disk /dev/sdb: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Disk /dev/sdb doesn't contain a valid partition table
		
Disk /dev/sdc: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Disk /dev/sdc doesn't contain a valid partition table
		
Disk /dev/sdd: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Disk /dev/sdd doesn't contain a valid partition table
		</screen>
		<para>So far so good! Next step is to create a partition of type <command>fd</command><indexterm><primary>fd (partition type)</primary></indexterm> on every disk. The fd type is to set the partition as <command>Linux RAID auto</command>. Like this screenshot shows. </para>
		<screen>
root@RHELv4u2:~# fdisk /dev/sdc
Device contains neither a valid DOS partition table, nor Sun, SGI or \
OSF disklabel
Building a new DOS disklabel. Changes will remain in memory only,
until you decide to write them. After that, of course, the previous
content won't be recoverable.
		
Warning: invalid flag 0x0000 of partition table 4 will be corrected b\
y w(rite)
		
Command (m for help): n
Command action
e   extended
p   primary partition (1-4)
p
Partition number (1-4): 1
First cylinder (1-130, default 1): 
Using default value 1
Last cylinder or +size or +sizeM or +sizeK (1-130, default 130): 
Using default value 130
		
Command (m for help): t
Selected partition 1
Hex code (type L to list codes): fd
Changed system type of partition 1 to fd (Linux raid autodetect)
		
Command (m for help): p
		
Disk /dev/sdc: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start     End      Blocks   Id  System
/dev/sdc1          1       130     1044193+  fd  Linux raid autodetect
		
Command (m for help): w
The partition table has been altered!
		
Calling ioctl() to re-read partition table.
Syncing disks.
root@RHELv4u2:~# 
		</screen>
		<para>Now all three disks are ready for RAID, so we have to tell the system what to do with these disks.</para>
		<screen>
root@RHELv4u2:~# fdisk -l
		
Disk /dev/sda: 12.8 GB, 12884901888 bytes
255 heads, 63 sectors/track, 1566 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          13      104391   83  Linux
/dev/sda2              14        1566    12474472+  8e  Linux LVM
		
Disk /dev/sdb: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start      End      Blocks   Id  System
/dev/sdb1          1        130     1044193+  fd  Linux raid autodetect
		
Disk /dev/sdc: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start      End      Blocks   Id  System
/dev/sdc1          1        130     1044193+  fd  Linux raid autodetect
		
Disk /dev/sdd: 1073 MB, 1073741824 bytes
255 heads, 63 sectors/track, 130 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
		
Device Boot      Start      End      Blocks   Id  System
/dev/sdd1          1        130     1044193+  fd  Linux raid autodetect
		</screen>
		<para>The next step used to be <emphasis>create the RAID table in <command>/etc/raidtab</command><indexterm><primary>/etc/raidtab</primary></indexterm></emphasis>. Nowadays, you can just issue the command <command>mdadm</command><indexterm><primary>mdadm(1)</primary></indexterm> with the correct parameters. The command below is split on two lines to fit this print, but you should type it on one line, without the backslash (\).</para>
		<screen>
root@RHELv4u2:~# mdadm --create /dev/md0 --chunk=64 --level=5 --raid-d\
evices=3 /dev/sdb1 /dev/sdc1 /dev/sdd1
mdadm: array /dev/md0 started.
		</screen>
		<para>Below a partial screenshot how fdisk -l sees the RAID5</para>
		<screen>
root@RHELv4u2:~# fdisk -l
		
&#060;cut&#062;
			
Disk /dev/md0: 2138 MB, 2138308608 bytes
2 heads, 4 sectors/track, 522048 cylinders
Units = cylinders of 8 * 512 = 4096 bytes
			
Disk /dev/md0 doesn't contain a valid partition table			
		</screen>
		<para>We will use this software RAID 5 array in the next topic, LVM.</para>
	</section>
	<section><title>/proc/mdstat</title>
	<para>The status of the raid devices can be seen in <command>/proc/mdstat</command><indexterm><primary>/proc/mdstat</primary></indexterm>. This example shows a RAID 5 in the process of rebuilding.</para>
	<screen>
[root@RHEL5 ~]# cat /proc/mdstat 
Personalities : [raid6] [raid5] [raid4] 
md0 : active raid5 sdg1[3] sdf1[1] sde1[0]
      1677056 blocks level 5, 64k chunk, algorithm 2 [3/2] [UU_]
      [=================>...]  recovery = 89.1% (747952/838528) finish\
=0.0min speed=25791K/sec
      
unused devices: &#062;none&#060;
	</screen>
	<para>This example shows an active software RAID 5.</para>
	<screen>
[root@RHEL5 ~]# cat /proc/mdstat 
Personalities : [raid6] [raid5] [raid4] 
md0 : active raid5 sdg1[2] sdf1[1] sde1[0]
      1677056 blocks level 5, 64k chunk, algorithm 2 [3/3] [UUU]
      
unused devices: &#062;none&#060;
	</screen>
	</section>
	<section><title>Removing a software RAID</title>
		<para>The software raid is visible in /proc/mdstat when active. To remove the raid completely so you can use the disks for other purposes, you first have to stop (de-activate) it with mdadm.</para>
		<screen>mdadm --stop /dev/mdadm</screen>
		<para>When stopped, you can remove the raid with mdadm.</para>
		<screen>mdadm --remove /dev/mdadm</screen>
		<para>The disks can now be repartitioned.</para>
	</section>
	<section><title>Practice RAID</title>
		<para>1. Add three virtual disks of 200MB each to the virtual Red Hat machine.</para>
		<para>2. Create a software RAID 5 on the three disks. (It is not necessary to put a filesystem on it)</para>
		<para>3. Verify with fdisk and in /proc/ that the RAID exists.</para>
		<para>4. (optional) Stop and remove the RAID, unless you want to use it in the next chapter LVM.</para>
	</section>
</section>
</chapter>
